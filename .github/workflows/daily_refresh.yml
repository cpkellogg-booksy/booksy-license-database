name: Daily Data Refresh

on:
  schedule:
    - cron: '0 8 * * *'  # Runs automatically at 8:00 AM UTC
  workflow_dispatch:     # Allows you to click "Run workflow" manually

permissions:
  contents: write

jobs:
  build_and_deploy:
    runs-on: ubuntu-latest

    steps:
      # 1. CHECKOUT CODE
      - name: Checkout Repository
        uses: actions/checkout@v3

      # 2. SETUP PYTHON
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      # 3. INSTALL LIBRARIES
      - name: Install Dependencies
        run: |
          pip install pandas keplergl requests psycopg2-binary
          
      # 4. RUN ETL PIPELINES (Fetch Fresh Data)
      - name: Run Florida ETL
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: python etl_fl.py || echo "⚠️ Warning: FL script encountered an issue (continuing...)"

      - name: Run Texas ETL
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: python etl_tx.py || echo "⚠️ Warning: TX script encountered an issue (continuing...)"

      # 5. GENERATE MAP & REDIRECT PAGE
      - name: Generate Map Files
        run: python generate_map.py

      # 6. UPLOAD ARTIFACTS (Crucial Fix: Saves both files)
      - name: Upload Site Assets
        uses: actions/upload-artifact@v4
        with:
          name: Booksy_Site_Assets
          path: |
            index.html
            kepler_map.html
          retention-days: 5

      # 7. DEPLOY TO GITHUB PAGES
      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./
          keep_files: true  # Ensures we don't accidentally delete existing history if needed
